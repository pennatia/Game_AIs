{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniMax Implementation | Tic Tac toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement the MiniMax Code, we will describe the dependencies and programming logic behind the system that we have implemented MiniMax into. \n",
    "\n",
    "To begin with, we leverage the framework provided in the TicTacProject_Incomplete.py file that was provided. In our case, as we have completed the module, we ahve renamed the file to \"TicTacProject.py\". This program is dependent upon a file that was originally called \"CheckWin_Incomplete.py\", which we have renamed \"AI_Checks.py\". Here, we implemented the various different levels of AI difficulty that are then called within the TicTacProject.py framework. \n",
    "\n",
    "**Please note**: both of these files are available in the .zip folder attached to this submission. The AI difficulty that calls my minimax algorithm has already been selected, so simply calling the file will have the player fight against my AI powered by the MiniMax algorithm. \n",
    "\n",
    "For the actual implementation of the MiniMax algorithm, we must rely upon the \"CheckWin2\" function defined in the AI_Checks.py program. This function will return the id (a 1 for human, 2 for AI) for a given board state entered. \n",
    "\n",
    "Having clarified that, we can now define our MiniMax function, following the logic below:\n",
    "\n",
    "- The minimax function will take in a boardstate, a depth parameter, and whether the layer is a maximizing or minimizing layer\n",
    "- The function will then check whether the current boardstate has a win, and return a negative score for a human win, a positive score of an AI win, and a 0 for a tie. \n",
    "- We then define two conditional statements, depending on whether the current layer is a Minimizing or Maximizing layer. \n",
    "- For each, we initiate a best-score which is virtually equal to negative or positive infinity respectively.\n",
    "- We iterate through the emtpy board space and place (depending on which state the miniMax is in) an AI or Player mark. We then call Minimax (recursively), on the board state as it exists with the provisional mark, but with the opposite settings. \n",
    "- We then update the scores and possible best moves given the recursion and the total scores(determined by the initial win conditional statements). \n",
    "\n",
    "In this way, the Minimax algorithm will recursively traverse to all of the board possibilities and return the best possible move. \n",
    "\n",
    "Please note that we have further included a small \"punishment\" regarding depth. As such, if the winning score comes from \"deeper\" than another, it will be penalised. This will allow us to automatically choose the move that maximizes the result for the AI in the quickest way possible. \n",
    "\n",
    "My implementation follows below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(place, depth, is_Max):\n",
    "    # Return negative value if Player Wins\n",
    "    if checkWin2(place) == 1:\n",
    "        return -100, 0\n",
    "\n",
    "    # Return positive value if AI wins\n",
    "    elif checkWin2(place) == 2:\n",
    "        return 100, 0\n",
    "\n",
    "    # Return 0 with a draw\n",
    "    elif checkWin2(place) == 0:\n",
    "        return 0, 0 \n",
    "\n",
    "\n",
    "    # Initiate the Maximizing Layer\n",
    "    if is_Max:\n",
    "\n",
    "        # Initiate Value to Maximize \n",
    "        BS = -1000\n",
    "        bestmove = 0\n",
    "\n",
    "        # Iterate through each board place\n",
    "        for i in range(len(place)):\n",
    "            if place[i] == 0:\n",
    "                # Place AI mark\n",
    "                place[i] = 2\n",
    "                \n",
    "                # Recursive Call, with Minimize (by having False)\n",
    "                score = minimax(place,depth+1,False)[0]\n",
    "\n",
    "                # Update Score, punishing depth\n",
    "                score = score - depth\n",
    "                place[i] = 0\n",
    "                if(score > BS):\n",
    "                    BS = score\n",
    "                    bestmove = i\n",
    "        return BS, bestmove\n",
    "    \n",
    "    if not is_Max:\n",
    "\n",
    "        # Initiate Value to Minimize\n",
    "        BS = 800\n",
    "        bestmove = 0\n",
    "\n",
    "        # Iterate through each board place\n",
    "        for i in range(len(place)):\n",
    "            if place[i] == 0:\n",
    "                # Place AI mark\n",
    "                place[i] = 1\n",
    "\n",
    "                # Recursive Call, with Minimize (by having False)\n",
    "                score = minimax(place,depth+1,True)[0]\n",
    "\n",
    "                # Update Score, punishing depth\n",
    "                score = score + depth\n",
    "                place[i] = 0\n",
    "                if(score < BS):\n",
    "                    BS = score \n",
    "                    bestmove = i\n",
    "        return BS, bestmove   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please note that our implementation can be found in the AI_Checks.py file attached to the .zip with this submission. You can then feel free to run the TicTacProject.py (also attached), and play against the MiniMax algorithm. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
